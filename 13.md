# Data Warehouse

**La maggior parte delle aziende dispone di enormi basi di dati contenenti informazioni di tipo operativo per i quali vi è il bisogno di sistemi per il supporto alle decisioni.** Con "supporto alle decisioni" facciamo riferimento alla Business Intelligence e alla Knowledge Discovery. La *Business Intelligence* è una disciplina di supporto alla decisione strategica aziendale il cui obiettivo è quello di **trasformare i dati aziendali in informazioni fruibili a diversi livelli di dettaglio e per applicazioni di analisi**, mentre *la Knowledge Discovery* è l’attività che consiste nell’**individuare ed estrarre da enormi volumi di dati tutta la conoscenza utile alle attività strategiche**. In questo contesto, i "dati" sono l'insieme delle informazioni contenute in un database, mentre i "pattern" sono espressioni che descrivono in modo succinto le informazioni estratte dai dati.

**Invece, il Data Warehousing è una collezione di metodi, tecnologie e strumenti di ausilio al “knowledge worker” per condurre analisi dei dati finalizzate all’attuazione di processi decisionali e al miglioramento del patrimonio informativo.** Nella fattispecie, **un data warehouse è una base di dati per il supporto alle decisioni, che è mantenuta separatamente dalle basi di dati operative dell’azienda**: è **orientata ai *soggetti di interesse*** (clienti, prodotti, vendite), si appoggia su **più fonti eterogenee** di dati e **rappresenta temporalmente l'evoluzione dei dati** in maniera non volatile (è cioè aggiornato ad intervalli regolari). Un *data mart* è un sottoinsieme dipartimentale del data warehouse.

Architetturalmente, un data warehouse deve separare l'elaborazione analitica da quella transazionale-operativa; deve essere capace di scalarale assieme ai suoi dati; deve poter integrare nuovi applicativi o base di dati; dev'essere sicuro e amministrabile. Esistono tre possibili architetture di un data warehouse:

- *Architettura a 1 livello*: Livello dei sorgenti (database) -> Livello del warehouse -> Livello di analisi (strumenti OLAP/reportistica).

- *Architettura a 2 livelli*: Livello dei sorgenti -> Livello di alimentazione (ETL) -> Livello del warehouse -> Livello degli `n` data mart -> Livello di analisi.

- *Architettura a 3 livelli*: La differenza qui è che, dopo l'ETL, i dati vengono "riconciliati" con quelli pre-ETL, per garantire la consistenza dei dati. Questo livello è chiamato *livello di staging*.

**Il ruolo degli strumenti ETL è quello di alimentare il data warehouse.** Le operazioni di questi strumenti vengono definite con il termine di *riconciliazione*. Svolgono il proprio compito in 4 fasi:
1. **Estrazione**: si estraggono i dati rilevanti dai databse sorgenti. L'estrazione è *statica* (primo popolamento del data warehouse), *incrementale* (aggiornamento periodico del data warehouse) o **guidata dalle sorgenti** (event-driven).
2. **Pulitura**: si migliora la qualità dei dati estratti usando dizionari appositi e applicando regole del dominio applicativo.
3. **Trasformazione**: i dati passano da un formato operazionale a quello del data warehouse. Si opera sia a livello di memorizzazione, sia a livello di unità di misura (tempo etc) per normalizzare i formati e stabilire corrispondenze fra campi equivalenti in sorgenti diversi (matching), così come ridurre il numero di campi e record rispetto alla sorgente (selection).
4. **Caricamento**: si caricano i dati sul data warehouse con modalità di refresh (data warehouse truncato e poi ricreato coi nuovi dati) o update (solo le novità).

## Modello multidimensionale e definizioni

**Il modello multidimensionale si usa per la rappresentazione e l’interrogazione dei dati nei data warehouse come *fatti* ed *eventi*.** Gli oggetti che influenzano il processo decisionale sono *fatti di un’organizzazione*. I fatti di interesse sono rappresentati in *cubi* in cui:
- Ogni *cella* contiene misure numeriche che quantificano il *fatto* da diversi punti di vista (evento);
- Ogni *asse* rappresenta una dimensione di interesse per l’analisi;
- Ogni *dimensione* può essere la radice di una gerarchia di attributi usati per aggregare i dati memorizzati nei cubi di base.

I principali elementi di un modello multidimensionale sono:

- Un *evento primario* è una particolare occorrenza di un fatto, individuata da una ennupla caratterizzata da un valore per ciascuna dimensione. 
- Un *evento secondario* è, dato un insieme di attributi dimensionali (pattern), ciascuna ennupla di questi valori che aggrega tutti gli eventi primari corrispondenti. 
- Le *gerarchie* definiscono il modo in cui gli eventi primari possono essere aggregati e selezionati significativamente per il processo decisionale. 
- La *dimensione* in cui una gerarchia ha radice ne definisce la *granularità* più fine di aggregazione. Agli attributi dimensionali corrispondono granularità via via crescenti. 
- I *metadati* sono dati usati per descrivere altri dati. Indicano le sorgenti, descrivono la struttura dei dati nel data warehouse, indicano il valore, l’uso e la funzione dei dati memorizzati, descrivono come i dati sono alterati e trasformati. Il contenitore dei metadati è strettamente collegato al data warehouse. Esistono due tipi di metadati: *interni* (di interesse per l'admin) ed *esterni* (di interesse per gli utenti).

**L'accesso ai "fatti" nel data warehouse avviene tramite *reportistica* o *OLAP*.** 

### Reportistica

**La reportistica è una modalità di accesso ai dati del data warehouse orientata ad utenti che devono accedere ad informazioni strutturate** in modo pressoché invariabile nel tempo. Il progettista può formulare l’interrogazione e renderla disponibile nel tempo. Un report è definito da una *interrogazione* (es: selezione ed aggregazione) e da una *presentazione* (tabellare/grafica).

### OLAP

**L'analisi dei dati OLAP (*On-Line Analytical Processing*) è la principale modalità di fruizione delle informazioni contenute in un data warehouse.** Consente agli utenti di esplorare interattivamente i dati sulla base del *modello multidimensionale*. L’analisi OLAP è caratterizzata da un insieme di operazioni che consentono di manipolare i dati in modo da ottenere informazioni utili per il processo decisionale. Le operazioni OLAP sono:

- **RESTRIZIONE - SLICING**: Consiste nello stabilire, per almeno una delle dimensioni di analisi un sottoinsieme, *un valore possibile* per tale attributo, e di escludere quei fatti che non sono associati a quello specifico valore. Come risultato si ottiene un cubo con un numero di dimensioni inferiore almeno di uno rispetto al cubo sorgente.

- **RESTRIZIONE - DICING**: Consiste nello stabilire, per almeno una delle dimensioni di analisi un sottoinsieme, *un insieme di valori possibili* per tale attributo, e di escludere quei fatti che non sono associati a nessuno di tali valori.

- **AGGREGAZIONE - ROLL UP**: *Consiste nel passare da una visualizzazione ad un livello di dettaglio più fine ad una visualizzazione ad un livello di dettaglio meno fine.*

- **AGGREGAZIONE - DRILL DOWN**: *Consiste nel passare da una visualizzazione ad un livello di dettaglio meno fine ad una visualizzazione ad un livello di dettaglio più fine.* Il dettaglio più essere aumentato di una dimensione percorrendo la gerarchia, oppure aggiungendo una intera dimensione.

- **AGGREGAZIONE - DRILL ACROSS**: Consiste nello stabilire un *confronto tra due o più cubi correlati in modo da ottenere una visualizzazione comparata* di due diverse misure e per il calcolo di misure derivate dai dati presenti sui cubi. Per fare ciò occorre che i metadati presenti nel data warehouse siano coordinati.

- **AGGREGAZIONE - DRILL THROUGH**: Consiste nel *passaggio dai dati aggregati multi-dimensionali del data warehouse ai dati operazionali presenti nelle sorgenti* o nel livello riconciliato.

- **PIVOTING**: L’operatore di pivoting consiste nel ruotare gli assi di visualizzazione del cubo dei fatti mantenendo invariato il livello di aggregazione ed il numero delle dimensioni: ciò incrementa la leggibilità delle stesse informazioni.

## Implementazione e ciclo di vita di un Data Warehouse

I fattori di rischio legati all'implementazione di un data warehouse riguardano la malagestione del progetto, le tecnologie, i dati, la progettazione. 

Esistono diversi approcci per diminuire questi fattori di rischio:

- **Approccio Top-Down**: con questo tipo di approccio è necessario analizzare i bisogni globali dell’intera azienda, pianificare lo sviluppo del data warehouse e progettarlo e realizzarlo nella sua interezza. 
    - Vantaggi: visione globale dell’obiettivo, data warehouse consistente e ben integrato.
    - Svantaggi: tempi lunghi di realizzazione, impossibilità di prevedere le esigenze particolari delle diverse aree aziendali.

- **Approccio Bottom-Up**: con questo tipo di approccio il data warehouse è costruito in modo incrementale e in funzione dei data mart; si creano i data mart, che sono concentrati su una specifica area di interesse; il primo data mart deve essere quello più strategico per l’azienda e deve ricoprire un ruolo centrale per l’intero data warehouse. Questo approccio ha un particolare ciclo di vita:
    - Definizione degli obiettivi e pianificazione, analisi di costi e rischi.
    - Progettazione dell’infrastruttura, dell'architettura e degli strumenti.
    - Progettazione e sviluppo dei Data Mart.

Progettazione, sviluppo e attuazione dei data warehouse si inseriscono nel contesto del *Business Dimensional Lifecycle*, che consiste in pianificazione, definizione dei requisiti, effettiva attuazione del data warehouse, manutenzione. Il *Rapid Warehousing Methodology* è un metodo di sviluppo iterativo che suddivide grossi progretti in sottoprogetti a basso rischio chiamate *build* (AGILE). In questo caso, le fasi del ciclo di vita includeranno anche l'accertamento della fattibilità, la costruzione/collaudo e il riesame prima del rilascio.

In generale, il ciclo di vita di un data warehouse è composto dalle seguenti fasi:
- **Fase di analisi e riconciliazione**. La prima produce una serie di schemi locali per ogni sorgente di dati; la seconda, a partire da un insieme di schemi locali, produce un unico schema rioncicliato che non presenti inconsistenze.
- **Fase di modellazione concettuali**, che produce un un insieme di schemi di fatto usando il DFM a partire da uno schema riconciliato.
- **Fase di modellazione logica**, che produce uno schema logico usando ROLAP o MOLAP a partire da un insieme di schemi di fatto.
- Progettazione e sviluppo dello strato di alimentazione (ETL)
- Sviluppo della UI, manutenzione, testing e rilascio

## Fase di analisi e riconciliazione

**L'analisi e riconciliazione delle fonti dati richiede di definire e documentare lo schema del livello dei dati operazionali a partire da quale verrà alimentato il data warehouse.** Riceve in ingresso gli schemi delle sorgenti e produce un insieme di metadati che modellano lo schema riconciliato e le corrispondenze tra gli elementi di quest’ultimo e quelli del sistema operazionale. Coinvolge figure che conoscono il dominio applicativo. A questo livello, il modello architetturale di riferimento è quello a tre livelli, nel quale si suppone che il livello di dati riconciliato esiste, la scelta ricade su questo modello perché l’**alimentazione diretta del data warehouse è un compito troppo complesso per essere eseguito in modo atomico**.

Dati gli schemi locali, la fase di analisi si articola in:

- **Ricognizione** (esame approfondito degli schemi locali mirato alla piena comprensione del dominio applicativo) e **normalizzazione** (mira a correggere gli schemi locali al fine di modellare in modo più accurato il dominio applicativo) dei diversi schemi locali che produce un insieme di schemi consistenti e completi.

- **Integrazione**, che produce *uno* schema concettuale globalmente consistente.
Consiste nella individuazione di corrispondenze tra i concetti degli schemi locali e nella risoluzione dei conflitti evidenziati. **Lo scopo è di creare un unico schema globale i cui elementi sono correlati con i corrispondenti elementi degli schemi locali** (mapping). In questa fase vanno anche identificati concetti distinti di schemi differenti che sono correlati attraverso proprietà semantiche (*proprietà inter-schema*). Per poter ragionare sui concetti degli schemi sorgente è necessario usare un unico formalismo (ER, UML, DTD ecc..) in modo da fissare i costrutti utilizzabili e la potenza espressiva.

### Problemi individuabili durante l'integrazione
1. *Diversità di prospettiva* sull'interpretazione del dominio applicativo.
2. *Diversità di formalismi*.
3. *Incompatibilità delle specifiche*: schemi diversi che modellano una stessa porzione del dominio applicativo racchiudono concetti diversi in contrasto tra loro.
    - *Concetti comuni*: quattro sono le possibili relazioni esistenti tra due distinte rappresentazioni locali `R1` e `R2` di uno stesso concetto:
        - *Identità*: si verifica quando vengono utilizzati gli stessi costrutti, il concetto è modellato dallo stesso punto di vista, quindi `R1` e `R2` coincidono.
        - *Equivalenza*: si verifica quando `R1` e `R2` non sono le stesse poiché sono stati utilizzati costrutti diversi ma equivalenti.
        - *Comparabilità*: questa situazione si verifica quando `R1` e `R2` non sono né identici né equivalenti ma, i costrutti utilizzati e i punti di vista dei progettisti non sono in contrasto tra loro.
        - *Incompatibilità*: questa situazione si verifica quando `R1` e `R2` sono in contrasto a causa  dell’incoerenza nelle specifiche, ovvero quando la realtà modellata da `R1` nega quella modellata da `R2`.
    - *Concetti correlati*: a seguito dell’integrazione, molti concetti diversi, ma correlati, verranno a trovarsi nello stesso schema dando vita a nuove relazione che non erano percepibili in precedenza. Tali relazioni sono dette proprietà inter-schema.

### Fasi dell'integrazione
1. *Preintegrazione*: Durante questa fase viene svolta l’analisi della sorgente dati, che porta a definire la politica generale dell’integrazione. Bisogna prendere decisioni sulle porzioni degli schemi che dovranno essere integrate e sulle strategie di integrazione.
2. *Comparazione degli schemi*: Questa fase consiste in un’analisi comparativa dei diversi schemi locali e mira a identificare correlazioni e conflitti tra concetti in essi espressi. I tipi di conflitti che possono essere evidenziati sono di diverso tipo:
    - *Di eterogeneità*: diversità dovute all’utilizzo di formalismi con diverso potere espressivo negli schemi sorgenti
    - *Semantici*: due schemi modellano la stessa porzioni di mondo reale ma a un livello diverso di astrazione
    - *Sui nomi*: differenze nelle terminologie utilizzate nei diversi schemi sorgenti (omonimie e sinonimie)
    - *Strutturali*: scelte diverse nella modellazione di uno stesso concetto, questi conflitti possono a loro volta essere di vario tipo:
        - *Di tipo*: uno stesso concetto è modellato utilizzando due costrutti diversi
        - *Di dipendenza*: due o più concetti sono correlati con dipendenze diverse in schemi diversi
        - *Di chiave*: per uno stesso concetto vengono utilizzati identificatori diversi in schemi diversi
        - *Di comportamento*: diverse politiche di cancellazione/modifica dei dati vengono adottate per uno stesso concetto in schemi diversi.
3. *Allineamento degli schemi*: Lo scopo di questa fase è la risoluzione dei conflitti evidenziati al passo precedente, mediante primitive di trasformazione degli schemi sorgenti o dello schema riconciliato temporaneo.
4. *Fusione e ristrutturazione degli schemi*: Nell’ultima fase gli schemi allenati vengono fusi per formare un unico schema riconciliato. Solitamente, si sovrappongono i concetti comuni a cui saranno collegati i rimanenti concetti degli schemi locali. Dopo questa operazione, ulteriori trasformazioni permetteranno di migliorare lo schema rispetto a:
    - *Leggibilità*: facilita e velocizza le successive fasi di progettazione
    - *Completezza*: ricerca di proprietà inter-schema non evidenziate in precedenza
    - *Minimalità*: eliminare ridondanza di concetti duplicati o comunque derivabili

Il risultato dell’analisi delle sorgenti operazionali è composto da due elementi:
- **Schema riconciliato**, in cui sono stati risolti i conflitti presenti tra gli schemi locali
- Insieme di corrispondenze tra gli elementi presenti negli schemi sorgenti e quello dello schema destinazione (necessarie per la fase di progettazione degli ETL). L’approccio per stabilire la corrispondenza tra i due livelli dell’architettura prevede che lo schema globale sia espresso in termini degli schemi sorgente. Con questo approccio, ad ogni concetto dello schema globale è associata una vista definita in base a concetti degli schemi sorgenti. Per fare ciò, si sostituisce ad ogni concetto dello schema globale la vista che lo definisce in termini di concetti degli schemi locali (unfolding).

## Modellazione concettuale e DFM

**La modellazione concettuale affronta il problema della traduzione dei requisiti in termini di un modello astratto, indipendente dal DBMS.** Non esistono standard di modello o di processo. Il modello Entity-relationship (ER) è diffuso come strumento di modellizzazione concettuale. Esso è però orientato alle *associazioni tra i dati* e non alla sintesi. È sufficientemente espressivo per rappresentare la maggior parte dei concetti, ma **non è in grado di mettere in luce il modello multidimensionale**. Altre possibilità: UML, Star Scheme (troppo orientati alle relazioni), DFM.

Il ***Dimensional Fact Model*** (DFM) è un modello concettuale concepito per il supporto allo sviluppo di Data Mart. È una specializzazione del modello multidimensionale per applicazioni di Data Warehousing. È pensato per:
- Supportare efficacemente il progetto concettuale
- Creare un ambiente su cui formulare in modo intuitivo le interrogazioni dell’utente
- Permettere il dialogo tra progettista e utente finale per raffinare le specifiche
- Creare una piattaforma stabile da cui partire per la modellazione logica
- Restituire una documentazione a posteriori espressiva e non ambigua. La rappresentazione concettuale generata dal DFM consiste in un insieme di schemi di fatto

Gli elementi di base modellati dagli schemi di fatto sono i fatti, le misure, le dimensione e le gerarchie.

La tecnica per la progettazione concettuale di un Data Warehouse a partire dalle sorgenti operazionali, secondo il DFM, consiste nei seguenti passi:
1. *Definizione dei fatti*
2. Per ciascun *fatto*...
    - *Costruzione dell’albero degli attributi*
    - *Potatura e innesto dell’albero degli attributi*
    - *Definizione di dimensioni e misure*
    - *Creazione dello schema di fatto*

### Costrutti di base del DFM

- Un **fatto** è un concetto di interesse per il processo decisionale. Tipicamente modella un insieme di eventi che accadono nell’impresa. È essenziale che un fatto abbia aspetti dinamici, ovvero evolva nel tempo. In uno schema ER un fatto può corrispondere a: Un’entità `F`; un’associazione `n`-aria `R` tra le entità `E1, E2,…, En`.
- Una **misura** è una proprietà numerica di un fatto e ne descrive un aspetto quantitativo di interesse per l’analisi. Uno schema di fatto si dice *vuoto* se non ha misure.
- Una **dimensione** è una proprietà con dominio finito di un fatto e ne descrive una *coordinata di analisi*. Un fatto esprime una associazione molti-a-molti tra le dimensioni. I fatti hanno natura dinamica, rappresentata da una dimensione temporale. 
- Un **evento primario** è una particolare occorrenza di un fatto, individuata da una ennupla costituita da un valore per ciascuna dimensione. A ciascun evento primario è associato un valore per ciascuna misura. Definiamo *evento* un’istanza che popola uno schema di fatto.
- Gli **attributi dimensionali** sono le dimensioni e gli attributi che descrivono tali dimensioni. Le relazioni tra gli attributi dimensionali sono espresse dalle gerarchie. 
- Una **gerarchia** è un albero direzionato i cui nodi sono attributi dimensionali e i cui archi modellano associazioni molti-a-uno tra coppie di attributi dimensionali. Racchiude una dimensione, posta alla radice dell’albero, e tutti gli attributi dimensionali che la descrivono.
    - Dato un insieme di attributi dimensionali, ciascuna ennupla di valori individua un **evento secondario** che aggrega tutti gli eventi primari corrispondenti. A ciascun evento secondario è associato un valore per ciascuna misura, che riassume in sé tutti i valori della stessa misura negli eventi primari corrispondenti.
- Gli **attributi descrittivi** specificano le proprietà degli attributi dimensionali di una gerarchia, e sono determinati tramite dipendenze funzionali. Un attributo descrittivo non può essere usato per identificare singoli eventi né per effettuare calcoli.
- Gli **attributi cross-dimensionali** sono attributi dimensionali o descrittivi il cui valore è determinato mediante la combinazione di due o più attributi dimensionali. Gli attributi dimensionali possono appartenere anche a gerarchie diverse.
- Un **arco multiplo** tra due attributi `a` e `b` indica che che ad ogni singolo valore di `a` possono corrispondere valori di `b`.
- Gli **archi opzionali** vengono impiegati per modellare associazioni dello schema di fatto non definite per un particolare sottoinsieme di eventi. 

#### Convergenza

La **convergenza** riguarda la struttura delle gerarchie.
- Sullo schema di fatto, **le convergenze sono denotate da due o più archi, in genere appartenenti alla stessa gerarchia, che terminano nello stesso attributo dimensionale.**
- In presenza di una gerarchia che non ha una struttura ad albero, non è più possibile determinare univocamente il verso degli archi e, per fare ciò, gli archi convergenti devono essere orientati.
- Attributi apparentemente uguali non determinano sempre una convergenza.
- Se uno dei percorsi alternativi non comprende attributi intermedi, non ha ragione di esistere: la convergenza è infatti del tutto ovvia grazie alla transitività delle dipendenze funzionali.

Una convergenza nello schema di fatto è del tutto trasparente ai fini dell’aggregazione. Per verificare la semantica dell’aggregazione in presenza di attributi cross-dimensionali, dobbiamo risalire agli eventi primari che includono l’attributo cross-dimensionale.

#### Albero degli attributi

Data un’entità `F` designata come fatto, si definisce **albero degli attributi** quello che soddisfa i seguenti requisiti:
- Ogni vertice corrisponde ad un attributo semplice o composto dello schema sorgente
- La radice corrisponde all’identificativo di `F`
- Per ogni vertice `v`, l’attributo corrispondente determina funzionalmente tutti gli attributi che corrispondono ai discendenti di `v`. In genere, Non tutti gli attributi dell’albero sono di interesse per il Data Mart, motivo per cui si opera la potatura di un vertice `v`: si effettua eliminando l’intero sottoalbero radicato in `v`. In alternativa, si può effettuare l'innesto di un vertice `v`: viene utilizzato quando, sebbene un vertice esprima un’informazione non interessante, è necessario mantenere nell’albero i suoi discendenti. 

I problemi dell'albero degli attributi sono i seguenti:
1. Presenza di un ciclo associazioni
2. Raggiungimento della medesima entità `E` attraverso cammini differenti
3. Presenza di associazioni `…-a-molti` e di attributi multipli
4. Presenza di associazioni o attributi opzionali
5. Presenza di associazioni `n`-arie
6. Presenza di gerarchie di specializzazione
7. Presenza di attributi composti

## Modellazione logica

**La progettazione logica definisce l’insieme dei passi per trasformare lo schema concettuale in uno schema logico.**

La progettazione logica dei Data Mart è profondamente diversa dai sistemi operazionali. **Nei data warehouse, l’obiettivo è quello di massimizzare la velocità del reperimento dei dati mentre nei sistemi operazionali si mira a minimizzare la quantità di informazione da memorizzare.**

I principali passi di questo processo sono:
- Traduzione degli schemi di fatto in schemi logici
- Materializzazione delle viste
- Frammentazione verticale ed orizzontale delle fact table

La traduzione dal DFM al modello logico non è del tutto automatica, richiedendo in alcuni momento l’intervento del progettista.

### Sistemi MOLAP

**I sistemi MOLAP memorizzano i dati usando strutture dati multidimensionali**, ad esempio vettori multidimensionali in cui ogni elemento è associato ad un insieme di coordinate nello spazio dei valori.

*Vantaggi*:
- Il tipo di struttura dati utilizzata è la **rappresentazione più naturale per i dati** di un data warehouse.
- Fornisce **ottime prestazioni** poiché si presta bene alle esecuzioni delle operazioni OLAP, che sono esprimibili direttamente sulla struttura dati e non hanno bisogno di essere simulate attraverso interrogazioni SQL.

*Svantaggi*:
- Vi è il problema della **sparsità dei dati**: solo una piccola porzione delle celle di un cubo contiene effettivamente informazioni, le rimanenti corrispondono ad eventi non accaduti. Questa comporta un forte spreco in termini di spazio su disco e di tempo per caricare i dati nel cubo. Questo problema non incide sui sistemi ROLAP, poiché essi consentono di memorizzare solo le celle di interesse.
- I diversi sistemi hanno in comune solo principi di base, ma non ci conoscono i dettagli implementativi, rendendo difficile la portabilità.
- **Non esistono standard di interrogazione che svolgano un ruolo simile a quello di SQL** nei sistemi relazionali.

### Sistemi ROLAP

**I sistemi ROLAP utilizzano il modello relazionale per la rappresentazione dei dati multidimensionali.** I motivi che spingono all’adozione di un modello relazione per modellare concetti multidimensionali sono i seguenti:
- Il **modello relazionale è lo standard “de facto” dei database**, ed è conosciuto dai professionisti del settore. L’evoluzione subita dai DBMS relazionali, da trent’anni sul mercato, li rende strumenti raffinati ed ottimizzati.
- L’**assenza di sparsità dei dati** garantisce maggiore scalabilità, che è fondamentale per database in continua crescita quali i data warehouse.

**Lo schema a stella si usa per la modellazione multidimensionale su sistemi ROLAP.** 

È composto da:
- Un insieme di relazioni `DT1…DTn`, chiamate *dimension table*, ciascuna associata ad una dimensione e caratterizzata da una chiave primaria e un insieme di attributi che descrivono le dimensioni a vari livelli di aggregazione
- Una relazione `FT`, chiamata *fact table*, la cui chiave primaria è data dall’insieme delle chiavi primarie delle dimension table. Inoltre, `FT` contiene un attributo per ogni misura.

Le *dimension table* non sono in 3NF, a causa della presenza di dipendenze funzionali transitive generate dalla presenza contemporanea di tutti gli attributi della gerarchia. La sparsità non rappresenta un problema, poiché nella *fact table* vengono memorizzate solo le combinazioni di chiavi per le quali effettivamente esiste l’informazione. 

**Uno schema snowflake è ottenibile da uno schema a stella** decomponendo una o più *dimension table* `DTi` in più tabelle `DT(i,1),…, DT(i,n)` al fine di eliminare alcune delle dipendenze funzionali transitive presenti. Lo schema snowflake normalmente non è raccomandato a causa della diminuzione dello spazio di memorizzazione che raramente è benefico, ma è utile quando parte di una gerarchia è condivisa tra le dimensioni, e per le viste materializzate che richiedono una rappresentazione aggregata delle dimensioni corrispondenti. 

### Viste

Una grande quantità di dati memorizzati nel datawarehouse potrebbe rendere l'informazione di difficile lettura da parte dell'utente. La soluzione è ridurre la porzione da esaminare attraverso operazioni di selezione ed aggregazione.
- Selezione: restringono la porzione di dati di interesse individuano quelli effettivamente interessanti per la specifica analisi 
- Aggregazione: riducono i dati collassando più elementi non aggregati in un unico elemento aggregato

L’aumento delle prestazioni è ottenuto precalcolando i dati aggregati di uso comune. Le *fact table* contenenti dati aggregati sono dette *viste*:
- *Viste primarie*: corrispondono a pattern primari (definito dall’insieme delle dimensioni)
- *Viste secondarie*: corrispondono a pattern secondari o sono individuate verificando se possono essere alimentate a partire da viste nel data warehouse (aggregati)
