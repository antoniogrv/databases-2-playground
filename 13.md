# Data Warehouse

La maggior parte delle aziende dispone di enormi basi di dati contenenti dati di tipo operativo per i quali vi è il bisogno di sistemi per il supporto alle decisioni. La Business Intelligence è una disciplina di supporto alla decisione strategica aziendale il cui obiettivo è quello di trasformare i dati 
aziendali in informazioni fruibili a diversi livelli di dettaglio e per applicazioni di analisi, mentre la Knowledge Discovery è l’attività che consiste nell’individuare ed estrarre da enormi volumi di dati tutta la conoscenza utile alle attività più strategiche. In questo contesto, i "dati" sono l'insieme delle informazioni contenute in un database, mentre i "pattern" sono espressioni che descrivono in modo succinto le informazioni estratte dai dati.

L'analisi dei dati (OLAP - On-Line Analytical Processing) è la principale modalità di fruizione delle informazioni contenute in un DW. Consente agli utenti di esplorare interattivamente i dati sulla base del modello multidimensionale. Invece, il Data Warehousing è una collezione di metodi, tecnologie e strumenti di ausilio al “knowledge worker” per condurre analisi dei dati finalizzate all’attuazione di processi decisionali e al miglioramento del patrimonio informativo. Nella fattispecie, un data warehouse è una base di dati per il supporto alle decisioni, che è mantenuta separatamente dalle basi di dati operative dell’azienda: è orientata ai soggetti di interesse (clienti, prodotti, vendite), si appoggia su più fonti eterogenee di dati e rappresenta temporalmente l'evoluzione dei dati in maniera non volatile (è cioè aggiornato ad intervalli regolari). Un data mart è un sottoinsieme dipartimentale del data warehouse.

Architetturalmente, un data warehouse deve separare l'elaborazione analitica da quella transazionale; deve essere capace di scalarale assieme ai suoi dati; deve poter integrare nuovi applicativi o base di dati; dev'essere sicuro e amministrabile. Esistono tre possibili architetture di un data warehouse:

[ARCHITETTURA DATA WAREHOUSE A 1 LIVELLO]
Livello dei sorgenti (database) -> Livello del warehouse -> Livello di analisi (strumenti OLAP/reportistica/what-if/data mining)

[ARCHITETTURA DATA WAREHOUSE A 2 LIVELLI]
Livello dei sorgenti -> livello di alimentazione (ETL e Metadati) -> Livello del warehouse -> Livello degli n data mart -> Livello di analisi

[ARCHITETTURA DATA WAREHOUSE A 3 LIVELLI]
La differenza qui è che, dopo l'ETL, i dati vengono "riconciliati" con quelli pre-ETL.

Il ruolo degli strumenti ETL è quello di alimentare una sorgente di dati che possa a sua volta alimentare il DW. Le operazioni di questi strumenti vengono definite con il termine di riconciliazione. Svolgono il proprio compito in 4 fasi:
1. Estrazione: si estraggono i dati rilevanti dai databse sorgenti. L'estrazione è statica (prima popolazione del DW), incrementale (aggiornamento periodico del DW) o guidata dalle sorgenti (notifica asincrona delle modifiche).
2. Pulitura: si migliora la qualità dei dati estratti usando dizionari appositi e applicando regole del dominio applicativo.
3. Trasformazione: i dati passano da un formato operazionale a quello del DW. Si opera sia a livello di memorizzazione, sia a livello di unità di misura (tempo etc) per normalizzare i formati e stabilire corrispondenze fra campi equivalenti in sorgenti diversi (matching), così come ridurre il numero di campi e record rispetto alla sorgente (selection).
4. Caricamento: si caricano i dati sul DW con modalità di refresh (DW truncato e poi ricreato coi nuovi dati) o update (solo le novità).

## Modello multidimensionale e definizioni

Il modello multidimensionale si usa per la rappresentazione e l’interrogazione dei dati nei DW. Gli oggetti che influenzano il processo decisionale sono fatti di un’organizzazione (vendite, spedizioni, ricoveri…). 
I fatti di interesse sono rappresentati in cubi in cui:
• ogni cella contiene misure numeriche che quantificano il fatto da diversi punti di vista (evento);
• ogni asse rappresenta una dimensione di interesse per l’analisi;
• ogni dimensione può essere la radice di una gerarchia di attributi usati per aggregare i dati memorizzati nei cubi di base.

Restringere i dati significa ritagliare una porzione dal cubo circoscrivendo il campo di analisi. La forma più semplice di restrizione è lo slicing. Consiste nel ridurre la dimensionalità del cubo fissando un valore per uno o più dimensioni.

Un evento primario è una particolare occorrenza di un fatto, individuata da una ennupla caratterizzata da un valore per ciascuna dimensione. Ad esempio, un evento primario potrebbe essere il “05/04/01” nel negozio “DiTutto” è stata venduta una quantità 3 con incassi 12 del prodotto “Brillo”. Un evento secondario è, dato un insieme di attributi dimensionali (pattern),ciascuna ennupla di questi valori che aggrega tutti gli eventi primari corrispondenti.Le gerarchie definiscono il modo in cui gli eventi primari possono essere aggregati e selezionati  significativamente per il processo decisionale. La dimensione in cui una gerarchia ha radice ne definisce la  granularità più fine di aggregazione. Agli attributi dimensionali corrispondono granularità via via crescenti. L’aggregazione richiede di definire un operatore adatto per comporre i valori delle misure che caratterizzano gli eventi primari in valori da abbinare a ciascun evento elementare.

I metadati sono dati usati per descrivere altri dati. Indicano le sorgenti, descrivono la struttura dei dati nel DW, indicano il valore, l’uso e la funzione dei dati memorizzati, descrivono come i dati sono alterati e trasformati. Il contenitore dei metadati è strettamente collegato al DW. Esistono due tipi di metadati: interni (di interesse per l'admin) ed esterni (di interesse per gli utenti).

La reportistica è una modalità di accesso ai dati del DW (l’altra modalità è OLAP) orientata ad utenti che devono accedere ad informazioni strutturate in modo pressoché invariabile nel tempo. Il progettista può formulare l’interrogazione e renderla disponibile nel tempo. Un report è definito da una interrogazione (es: selezione ed aggregazione) e da una presentazione (tabellare/grafica). 

## Operazioni OLAP

- **RESTRIZIONE - SLICING**: E’ il processo per cui si fissa un valore per almeno uno degli attributi dimensionali e si escludono dall’analisi tutti quegli eventi che non presentano tale valore. Come risultato si ottiene un cubo con un numero di dimensioni inferiore almeno di uno rispetto al cubo sorgente.

- **RESTRIZIONE - DICING**: Consiste nello stabilire per almeno una delle dimensioni di analisi un sottoinsieme di valori possibili per tale attributo e di escludere quei fatti che non sono associati a nessuno di tali valori.

- **AGGREGAZIONE - ROLL UP**: Consiste nel passare da una visualizzazione ad un livello di dettaglio più fine ad una visualizzazione ad un livello di dettaglio meno accurato.

- **AGGREGAZIONE - DRILL DOWN**: Consiste nel passare da una visualizzazione ad un livello di dettaglio più grosso ad una visualizzazione ad un livello di dettaglio più accurato. Il dettaglio più essere aumentato o aumentando di una dimensione percorrendo la gerarchia (raggruppare per città e mese -> raggruppare per negozio e mese) oppure aggiungendo una intera dimensione (raggruppare per prodotto -> raggruppare per prodotto e città).

- **AGGREGAZIONE - DRILL ACROSS**: Consiste nello stabilire un confronto tra due o più cubi correlati in modo da ottenere una visualizzazione comparata di due diverse misure e per il calcolo di misure derivate dai dati presenti sui cubi. Per fare ciò occorre che i metadati presenti nel DW siano coordinati.

- **AGGREGAZIONE - DRILL THROUGH**: Consiste nel passaggio dai dati aggregati multi dimensionalmente del DW ai dati operazionali presenti nelle sorgenti o nel livello riconciliato.

- **PIVOTING**: L’operatore di pivoting consiste nel ruotare gli assi di visualizzazione del cubo dei fatti mantenendo invariato il livello di aggregazione ed il numero delle dimensioni: ciò incrementa la leggibilità delle stesse informazioni.

## Implementazione e ciclo di vita di un Data Warehouse

Esistono due approcci per implementare un data warehouse:
- **ROLAP: Relational OLAP**: Viene utilizzato su DBMS relazionali, sono necessarie tipologie specifiche di schemi per traslare il modello multidimensionale su attributi, relazioni e vincoli di integrità. Presenta ridondanza e ha basse prestazioni dovute a costose operazioni di JOIN.
- **MOLAP: Muldimensional OLAP**: Viene utilizzato su DBMS multidimensionali, è un modello ad hoc ed accesso di tipo posizionale, le operazioni multidimensionali sono realizzabili in modo semplice senza ricorrere a JOIN questo porta ad ottime prestazioni.

I fattori di rischio legati all'implementazione di un DW riguardano la malagestione del progetto, le tecnologie, i dati, la progettazione. 

Esistono diversi approcci per diminuire questi fattori di rischio:

- Approccio Top-Down: con questo tipo di approccio è necessario analizzare i bisogni globali dell’intera azienda, pianificare lo sviluppo del DW e progettarlo e realizzarlo nella sua interezza. 
    - Vantaggi: visione globale dell’obiettivo, DW consistente e ben integrato.
    - Svantaggi: Tempi lunghi di realizzazione, complessità nell’analisi e nella riconciliazione di tutte le fonti, impossibilità di prevedere le esigenze particolari delle diverse aree aziendali.

- Approccio Bottom-Up: con questo tipo di approccio il DW è costruito in modo incrementale, i Data mart sono concentrati su una specifica area di interesse, il primo Data mart deve essere quello più strategico per l’azienda e deve ricoprire un ruolo centrale per l’intero DW. Questo approccio ha un particolare ciclo di vita:
    - Definizione degli obiettivi e pianificazione: individuazione obiettivi e confini del sistema, stima delle dimensioni, valutazione dei costi e del valore aggiunto, scelta dell’approccio per la costruzione, analisi dei rischi e delle aspettative
    - Progettazione dell’infrastruttura: scelte architetturali e degli strumenti
    - Progettazione e sviluppo dei Data Mart

Progettazione, sviluppo e attuazione dei DW si inseriscono nel contesto del Business Dimensional Lifecycle, che consiste in pianificazione, definizione dei requisiti, effettiva attuazione del DW, manutenzione. Il Rapid Warehousing Methodology è un altro metodo di sviluppare DW iterativamente che suddivide grossi progretti in sottoprogetti a basso rischio chiamate build. In questo caso, le fasi del ciclo di vita si estendono includendo anche l'accertamento della fattibilità, la costruzione/collaudo e il riesame prima del rilascio.

Un Data Mart si progetta analizzando le sorgenti e i requisiti; poi si effettua la progettazione concettuale usando il DFM (Dimensional Fact Model), poi si raffina e si valida lo schema concettuale (formulando le interrogazioni tipiche del Data Mart), poi progettazione logica (ROLAP o MOLAP), progettazione dell'alimentazione  e progettazione fisica.

## Fase di analisi e riconciliazione delle fonti dei dati

L'analisi e riconciliazione delle fonti dati richiede di definire e documentare lo schema del livello dei dati operazionali, a partire da quale verrà alimentato il Dat mart. Riceve in ingresso gli schemi delle sorgenti e produce un insieme di metadatiche modellano lo schema riconciliato e le corrispondenze tra gli elementi di quest’ultimo e quelli del sistema operazionale. Le figure coinvolte sono: il progettista e l’amministratore dei database operazionali in quanto la sua conoscenza del dominio applicativo è indispensabili per normalizzare gli schemi. A questo livello il modello architetturale di riferimento è quello a tre livelli, nel quale si suppone che il livello di dati riconciliato esiste, la scelta ricade su questo modello perché l’alimentazione diretta del DW è un compito troppo complesso per essere eseguito in modo atomico.

Dati gli schemi logici, la fase di analisi si articola in:

- Ricognizione (esame approfondito degli schemi locali mirato alla piena comprensione del dominio applicativo) e normalizzazione (mira a correggere gli schemi locali al fine di modellare in modo più accurato il dominio applicativo) dei diversi schemi locali che produce un insieme di schemi concettuali, localmente consistenti e completi (va svolta anche in presenza di una sola sorgente dati, con più sorgenti viene ripetuta per ogni singolo schema locale).

- Integrazione che produce uno schema concettuale globalmente consistente.
Consiste nella individuazione di corrispondenze tra i concetti degli schemi locali e nella risoluzione dei conflitti evidenziati. Lo scopo è di creare un unico schema globale i cui elementi sono correlati con i corrispondenti elementi degli schemi locali (mapping). In questa fase vanno anche identificati concetti distinti di schemi differenti che sono correlati attraverso proprietà semantiche (proprietà inter-schema). Per poter ragionare sui concetti degli schemi sorgente è necessario usare un unico formalismo (ER, UML, DTD ecc..) in modo da fissare i costrutti utilizzabili e la potenza espressiva. 

### Problemi individuabili durante l'integrazione
1. Diversità di prospettiva: il punto di vista rispetto al quale diversi gruppi di utenti vedono uno stesso oggetto del dominio applicativo può differenziarsi in base agli aspetti per la funzione a cui essi sono preposti.
2. Equivalenza dei costrutti del modello: i formalismi di modellazione permettono di rappresentare uno stesso concetto utilizzando combinazioni diverse dei costrutti a disposizione.
3. Incompatibilità delle specifiche: schemi diversi che modellano una stessa porzione del dominio applicativo racchiudono concetti diversi, in contrasto tra loro. Tali diversità possono coinvolgere ad esempio la scelta dei nomi, dei tipi di dati e dei vincoli di integrità.
4. Concetti comuni: quattro sono le possibili relazioni esistenti tra due distinte rappresentazioni R1 e R2 di uno stesso concetto:
    - Identità: si verifica quando vengono utilizzati gli stessi costrutti, il concetto è modellato dallo stesso punto di vista, quindi R1 e R2 coincidono.
    - Equivalenza: si verifica quando R1 e R2 non sono le stesse poiché sono stati utilizzati costrutti diversi ma equivalenti.
    - Comparabilità: questa situazione si verifica quando R1 e R2 non sono né identici né equivalenti ma, i costrutti utilizzati e i punti di vista dei progettisti non sono in contrasto tra loro.
    - Incompatibilità: questa situazione si verifica quando R1 e R2 sono in contrasto a causa  dell’incoerenza nelle specifiche, ovvero quando la realtà modellata da R1 nega quella modellata da R2.
5. Concetti correlati: a seguito dell’integrazione, molti concetti diversi, ma correlati, verranno a trovarsi nello stesso schema dando vita a nuove relazione che non erano percepibili in precedenza. Tali relazioni sono dette proprietà inter-schema.

### Fasi dell'integrazione
1. Preintegrazione: Durante questa fase viene svolta l’analisi della sorgente dati, che porta a definire la politica generale dell’integrazione. Bisogna prendere decisioni sulle porzioni degli schemi che dovranno essere integrate e sulle strategie di integrazione.
2. Comparazione degli schemi: Questa fase consiste in un’analisi comparativa dei diversi schemi e mira a identificare correlazioni e conflitti tra concetti in essi espressi. I tipi di conflitti che possono essere evidenziati sono di diverso tipo:
    - Di eterogeneità: diversità dovute all’utilizzo di formalismi con diverso potere espressivo negli schemi sorgenti
    - Semantici: due schemi modellano la stessa porzioni di mondo reale ma a un livello diverso di astrazione
    - Sui nomi: differenze nelle terminologie utilizzate nei diversi schemi sorgenti (omonimie e sinonimie)
    - Strutturali: scelte diverse nella modellazione di uno stesso concetto, questi conflitti possono a loro volta essere di vario tipo:
        - Di tipo: uno stesso concetto è modellato utilizzando due costrutti diversi
        - Di dipendenza: due o più concetti sono correlati con dipendenze diverse in schemi diversi
        - Di chiave: per uno stesso concetto vengono utilizzati identificatori diversi in schemi diversi
        - Di comportamento: diverse politiche di cancellazione/modifica dei dati vengono adottate per uno stesso concetto in schemi diversi.
3. Allineamento degli schemi: Lo scopo di questa fase è la risoluzione dei conflitti evidenziati al passo precedente, mediante primitive di trasformazione degli schemi sorgenti o dello schema riconciliato temporaneo. Alcune primitive tipiche riguardano il cambio dei nomi e dei tipi degli attributi, la modifica delle dipendenze funzionali e dei vincoli sugli schemi. È qui che il progettista definisce il mapping tra gli elementi degli schemi sorgenti e quelli dello schema riconciliato.
4. Fusione e ristrutturazione degli schemi: Nell’ultima fase gli schemi allenati vengono fusi per formare un unico schema riconciliato, solitamente si sovrappongono i concetti comuni a cui saranno collegati i rimanenti concetti degli schemi locali. Dopo questa operazione ulteriori trasformazioni permetteranno di migliorare lo schema rispetto a:
    - Leggibilità: facilita e velocizza le successive fasi di progettazione
    - Completezza: ricerca di proprietà inter-schema non evidenziate in precedenza
    - Minimalità: eliminare ridondanza di concetti duplicati o comunque derivabili

Il risultato dell’analisi delle sorgenti operazionali è composto da due elementi:
- Schema riconciliato, in cui sono stati risolti i conflitti presenti tra gli schemi locali
- Insieme di corrispondenze tra gli elementi presenti negli schemi sorgenti e quello dello schema destinazione (necessarie per la fase di progettazione degli ETL).
L’approccio per stabilire la corrispondenza tra i due livelli dell’architettura prevede che lo schema globale sia espresso in termini degli schemi sorgente detto GAV (Global as view). Con questo approccio ad ogni concetto dello schema globale è associata una vista definita in base a concetti degli schemi sorgenti. Per fare ciò con  il GAV si sostituisce ad ogni concetto dello schema globale la vista che lo definisce in termini di concetti degli schemi locali (unfolding).

## Modellazione concettuale e DFM

La tecnica per la progettazione concettuale di un Data Mart a partire dalle sorgenti operazionali, secondo il DFM, consiste nei seguenti passi:
1. Definizione dei fatti;
2. Per ciascun fatto,
    - Costruzione dell’albero degli attributi
    - Potatura e innesto dell’albero degli attributi
    - Definizione delle dimensioni/misure.
    - Creazione dello schema di fatto

La modellazione concettuale affronta il problema della traduzione dei requisiti in termini di un modello astratto, indipendente dal DBMS. Non esistono standard di modello o di processo. Il modello Entity-relationship (ER) è diffuso come strumento di modellizzazione concettuale dei Data mart. Esso è però orientato alle associazioni tra i dati e non alla sintesi. È sufficientemente espressivo per rappresentare la maggior parte dei concetti, ma non è in grado di mettere in luce il modello multidimensionale. Altre possibilità: UML, Star Scheme (troppo orientati alle relazioni), DFM.

Il Dimensional Fact Model (DFM) è un modello concettuale concepito per il supporto allo sviluppo di Data Mart. È una specializzazione del modello multidimensionale per applicazioni di Data warehousing. È un modello concettuale grafico per Data mart, pensato per:
- Supportare efficacemente il progetto concettuale;
- Creare un ambiente su cui formulare in modo intuitivo le interrogazioni dell’utente;
- Permettere il dialogo tra progettista e utente finale per raffinare le specifiche dei requisiti;
- Creare una piattaforma stabile da cui partire per il progetto logico (indipendentemente dal modello logico target);
- Restituire una documentazione a posteriori espressiva e non ambigua. La rappresentazione concettuale generata dal DFM consiste in un insieme di schemi di fatto.
- Gli elementi di base modellati dagli schemi di fatto sono i fatti, le misure, le dimensione e le gerarchie.

### Costrutti di base del DFM
- Un fatto è un concetto di interesse per il processo decisionale. Tipicamente modella un insieme di eventi che accadono nell’impresa (ES: vendite, spedizioni). È essenziale che un fatto abbia aspetti dinamici ovvero evolva nel tempo. In uno schema ER un fatto può corrispondere a: Un’entità F; Un’associazione n-aria R tra le entità E1, E2,…, En.
- Una misura è una proprietà numerica di un fatto e ne descrive un aspetto quantitativo di interesse per l’analisi (ES: ogni vendita è misurata dal suo incasso). Le misure vengono in genere usate per effettuare calcoli. Uno schema di fatto si dice vuoto se non ha misure.
- Una dimensione è una proprietà con dominio finito di un fatto e ne descrive una coordinata di analisi (dimensioni, tipiche per il fatto vendite sono prodotto, negozio, data). Un fatto esprime una associazione molti-a-molti tra le dimensioni. I fatti hanno natura dinamica, rappresentata da una dimensione temporale. 
- Un evento primario è una particolare occorrenza di un fatto, individuata da una ennupla costituita da un valore per ciascuna dimensione. A ciascun evento primario è associato un valore per ciascuna misura. Definiamo evento un’istanza che popola uno schema di fatto. Gli eventi possono essere aggregati rispetto i valori degli attributi lungo le gerarchie.
- Gli attributi dimensionali sono le dimensioni e gli attributi che le descrivono.Le relazioni tra gli attributi dimensionali sono espresse dalle gerarchie. 
- Una gerarchia è un albero direzionato i cui nodi sono attributi dimensionali e i cui archi modellano associazioni molti-a-uno tra coppie di attributi dimensionali. Racchiude una dimensione, posta alla radice dell’albero, e tutti gli attributi dimensionali che la descrivono.
- Dato un insieme di attributi dimensionali, ciascuna ennupla di valori individua un evento secondario che aggrega tutti gli eventi primari corrispondenti. A ciascun evento secondario è associato un valore per ciascuna misura, che riassume in sé tutti i valori della stessa misura negli eventi primari corrispondenti.
- Gli attributi descrittivi specificano le proprietà degli attributi dimensionali di una gerarchia, e sono determinati tramite dipendenze funzionali. Non possono essere usati per l’aggregazione poiché hanno spesso domini con valori continui. Un attributo descrittivo non può essere usato per identificare singoli eventi né per effettuare calcoli.
- Attributi cross-dimensionali: sono attributi dimensionali o descrittivi il cui valore è determinato mediante la combinazione di due o più attributi dimensionali.Gli attributi dimensionali possono appartenere anche a gerarchie diverse.
- Nel momento in cui un attributo entra in una dimensione piuttosto che in un attributo qualsiasi, il caso diventa più complesso. Infatti, è possibile aggregare i ricoveri in base alle diagnosi in uscita, ma anche selezionare le diagnosi in base ai ricoveri. 
-- Un arco multiplo tra due attributi a e b indiche che ad ogni singolo valore di a possono corrispondere valori di b.
- Gli archi opzionali vengono impiegati per modellare associazioni dello schema di fatto non definite per un particolare sottoinsieme di eventi. Si rappresenta con un trattino sull’arcoSe r è l’arco opzionale, bisogna distinguere se esso determina un attributo o una dimensione. Se r determina la dimensione di allora essa è opzionale, ossia esistono alcuni eventi primari identificati solo dalle altre dimensioni.
- Se esistono più archi opzionali uscenti da uno stesso attributo è possibile definire la copertura, ossia stabilire una relazione tra le diverse opzionalità. Sia a un attributo dimensionale con archi opzionali verso i propri figli b1,…,bm. Allora la copertura si dice: Totale se per ogni valore di a è sempre associato almeno un valore dei figli o parziale se esistono valori di a per i quali tutti i figli sono indefiniti; Esclusivo se per ogni valore di a si ha al massimo un valore per uno dei figli o sovrapposta se invece esistono valori di a abbinati a due o più figli

La convergenza riguarda la struttura delle gerarchie.
- Sullo schema di fatto le convergenze sono denotate da due o più archi, in genere appartenenti alla stessa gerarchia, che terminano nello stesso attributo dimensionale.
- In presenza di una gerarchia che non ha una struttura ad albero non è più possibile determinare univocamente il verso degli archi e, per fare ciò, gli archi convergenti devono essere orientati.
- Attributi apparentemente uguali non determinano sempre una convergenza.
- Se uno dei percorsi alternativi non comprende attributi intermedi, non ha ragione di esistere: la convergenza è infatti del tutto ovvia grazie alla transitività delle dipendenze funzionali.

Negli schemi di fatto spesso si rende necessario duplicare intere porzioni di gerarchie e ciò comporta l’uso di diversi nomi per evitare ambiguità. Tramite le gerarchie condivise si introduce una notazione grafica abbreviata che migliora la leggibilità dello schema. Si introducono quando si hanno significati diversi per lo stesso tipo di dati e il significato viene espresso inserendo il ruolo sull’arco entrante della gerarchia

Una convergenza nello schema di fatto è del tutto trasparente ai fini dell’aggregazione. Per verificare la semantica dell’aggregazione in presenza di attributi cross-dimensionali dobbiamo risalire agli eventi primari che includono l’attributo cross-dimensionale.
- Ciascun evento primario è associato ad un prodotto e ad un negozio (quindi ad una categoria e ad un posto)
- Essendo definito univocamente un valore di IVA per ogni evento primario, gli eventi secondari sui pattern che includono IVA risultano immediatamente determinati

Albero degli attributi: data un’entità F designata come fatto, si definisce albero degli attributi quello che soddisfa i seguenti requisiti:
- Ogni vertice corrisponde ad un attributo semplice o composto dello schema sorgente;
- La radice corrisponde all’identificativo di F.
- Per ogni vertice v, l’attributo corrispondente determina funzionalmente tutti gli attributi che 
corrispondono ai discendenti di v. In genere, non tutti gli attributi dell’albero sono di interesse per il Data mart. Potatura di un vertice v: si effettua eliminando l’intero sottoalbero radicato in v. Innesto di un vertice v: viene utilizzato quando, sebbene un vertice esprima un’informazione non interessante, è necessario mantenere nell’albero i suoi discendenti. Problemi:
    1. Presenza di un ciclo associazioni … -a-1(loop);
    2. Raggiungimento della medesima entità E attraverso cammini differenti.
    3. Presenza di associazioni …-a-molti e di attributi multipli.
    4. Presenza di associazioni o attributi opzionali.
    5. Presenza di associazioni n-arie.
    6. Presenza di gerarchie di specializzazione.
    7. Presenza di attributi composti.

## Modellazione logica

La progettazione logica definisce l’insieme dei passi per trasformare lo schema concettuale in uno schema logico. 
La progettazione logica dei Data Mart è profondamente diversa dai sistemi operazionali:
- Nei DW l’obiettivo è quello di massimizzare la velocità del reperimento dei dati mentre nei sistemi operazionali si mira a minimizzare la quantità di informazione da memorizzare. 

I principali passi di questo processo sono:
- Traduzione degli schemi di fatto in schemi logici;
- Materializzazione delle viste;
- Frammentazione verticale ed orizzontale delle fact table.

Uno schema di fatto può essere modellato in ambito relazionale mediante uno schema a stella in cui la fact table contiene tutte le misure e gli attributi descrittivi e, per ogni gerarchia, viene creata una dimension table che ne contiene tutti gli attributi. La traduzione dal DFM al modello logico non è del tutto automatica, richiedendo in alcuni momento l’intervento del progettista.

Esistono due distinti modelli logici per rappresentare la struttura multidimensionale dei dati:
- Quello relazionale, che dà luogo ai sistemi ROLAP (Relation On-Line Analytical Processing);
- Quello multidimensionale, che dà luogo ai sistemi MOLAP (Multidimensional On-Line Analytical 
Processing)
La maggior parte del mercato è orientata ai sistemi ROLAP, a causa di un insieme di problemi relativi al 

**[SISTEMA MOLAP]**
I sistemi MOLAP memorizzano i dati usando strutture dati multidimensionali, ad esempio vettori multidimensionali in cui ogni elemento è associato ad un insieme di coordinate nello spazio dei valori.
Vantaggi:
- Il tipo di struttura dati utilizzata è la rappresentazione più naturale per i dati di un DW;
- Fornisce ottime prestazioni poiché si presta bene alle esecuzioni delle operazioni OLAP, che sono esprimibili direttamente sulla struttura dati e non hanno bisogno di essere simulate attraverso interrogazioni SQL.
Svantaggi:
- Sparsità dei dati;
- Mancanza di standard, i diversi sistemi hanno in comune solo principi di base (ES. strutture dati), ma non ci conoscono i dettagli implementativi;
- Non esistono standard di interrogazione che svolgano un ruolo simile a quello di SQL nei sistemi relazionali.
- Problema della sparsità: solo una piccola porzione delle celle di un cubo contiene effettivamente informazioni, le rimanenti corrispondono ad eventi non accaduti. Questa comporta un forte spreco in termini di spazio su disco e di tempo per caricare i dati nel cubo. Questo problema non incide sui sistemi ROLAP, poiché essi consentono di memorizzare solo le celle di interesse.

**[SISTEMI ROLAP]**
Utilizzano il modello relazionale per la rappresentazione dei dati multidimensionali;I motivi che spingono all’adozione di un modello bidimensionale per modellare concetti multidimensionali sono i seguenti:
- Il modello relazionale è lo standard “de facto” dei database, ed è conosciuto dai professionisti del settore.
- L’evoluzione subita dai DBMS relazionali, da trent’anni sul mercato, li rende strumenti raffinati ed ottimizzati.
- L’assenza di sparsità dei dati garantisce maggiore scalabilità, fondamentale per database in continua crescita quali i DW.

Lo schema a stella si usa per la modellazione multidimensionale su sistemi ROLAP. È composto da:
- Un insieme di relazioni DT1… DTn, chiamate dimension table, ciascuna associata ad una dimensione e caratterizzata da una chiave primaria di ed un insieme di attributi che descrivono le dimensioni a vari livelli di aggregazione. 
- Una relazione FT, chiamata fact table, la cui chiave primaria è data dall’insieme delle chiavi primarie delle dimension table. 
- Inoltre, FT contiene un attributo per ogni misura.
Alla chiave di un dimension table si possono riferire più fact table, se le gerarchie sono conformi. Le dimension table non sono in 3NF, a causa della presenza di dipendenze funzionali transitive generate dalla presenza contemporanea di tutti gli attributi della gerarchia.La sparsità non rappresenta un problema, poiché nella fact table vengono memorizzate solo le combinazioni di chiavi per le quali effettivamente esiste l’informazione. Uno schema snowflake è ottenibile da uno schema a stella decomponendo una o più dimension table DTi in più tabelle DT(i,1),…, DT(i,n), al fine di eliminare alcune delle dipendenze funzionali transitive presenti. 
Ogni dimension table è caratterizzata da:
- Una chiave primaria d(i,j) (di solito surrogata);
- Un sottoinsieme degli attributi di DT(i) che dipendono funzionalmente da d(i,j);
- Zero o più chiavi esterne riferite ad altre DT(t,k) necessarie a garantire la ricostruibilità del contenuto informativo di DT(i). 
Le dimension table primarie sono quelle in cui le chiavi sono importate nella fact table, secondarie le altre. Lo schema snowflake normalmente non è raccomandato a causa della diminuzione dello spazio di memorizzazione raramente è benefico, ma è utile quando parte di una gerarchia è condivisa tra le dimensioni e per le viste materializzate che richiedono una rappresentazione aggregata delle dimensioni corrispondenti. 

### Viste
Problema: Analisi utente rese difficili dalla quantità di dati memorizzati nel DW.
Soluzione: Ridurre la porzione da esaminare attraverso operazioni di:
- Selezione: restringono la porzione di dati di interesse individuano quelli effettivamente interessanti per la specifica analisi. 
- Aggregazione: riducono i dati collassando più elementi non aggregati in un unico elemento aggregato.

L’aumento delle prestazioni è ottenuto precalcolando i dati aggregati di uso comune. Le fact table contenenti dati aggregati sono dette viste:
- Viste primarie: corrispondono a pattern primari (definito dall’insieme delle dimensioni);
- Viste secondarie: corrispondono a pattern secondari o sono individuate verificando se possono essere alimentate a partire da viste nel DW (aggregati)
